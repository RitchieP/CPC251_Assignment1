{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_model function will train the model by using Gradient Descent estimation for the parameters. It starts off by randomly initializing the weights with numbers between 0 to 9. Then, it will start estimating the parameters via gradient descent.\n",
    "\n",
    "The steps for this part is as follows:\n",
    "> 1. Randomly initialize the weights\n",
    "> 2. Calculate the cost for this model\n",
    "> 3. Improve the weights by estimating via Gradient Descent algorithm\n",
    "> 4. Return the estimated weights and cost history\n",
    "\n",
    "#### References used\n",
    "\n",
    "https://medium.com/geekculture/linear-regression-from-scratch-in-python-without-scikit-learn-a06efe5dedb6\n",
    "\n",
    "https://www.geeksforgeeks.org/how-to-implement-a-gradient-descent-in-python-to-find-a-local-minimum/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, alpha, max_epoch):\n",
    "    \"\"\" Pass four arguments\n",
    "        Arguments:\n",
    "            X: input features\n",
    "            y: responses\n",
    "            alpha: learning rate\n",
    "            max_epoch: maximum epochs\n",
    "        Returns:\n",
    "            w: estimated weights\n",
    "            hist_loss: training loss history\n",
    "    \"\"\"\n",
    "    hist_loss = []\n",
    "    # Initialize weights with random values\n",
    "    w = np.array(np.random.randint(0, 9, np.shape(X)[1]))\n",
    "\n",
    "    # We calculate the loss function for the first randomly initialized weights, and store it\n",
    "    y_pred = prediction(w, X)\n",
    "    current_loss = loss_fn(y, y_pred)\n",
    "    n = len(y)\n",
    "\n",
    "    for i in range(max_epoch):\n",
    "        # Estimate the parameter using the randomly initialized weights and loss function for it\n",
    "        gradient = -(np.matmul((y-y_pred), X))/n\n",
    "        w = w - alpha * gradient\n",
    "\n",
    "        # Predict with the new weights, and calculate the loss function for it, and store it\n",
    "        y_pred = prediction(w, X)\n",
    "        current_loss = loss_fn(y, y_pred)\n",
    "        hist_loss.append(current_loss)\n",
    "\n",
    "    return w, hist_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function\n",
    "\n",
    "The helper function here is used to help in splitting the dataset into training and testing data. Very much like Scikit Learn's train_test_split function. It first calculates the number of datas to be taken based on the splitting ratio pre-defined. Then it will obtain a random order of indexes based on the number of rows of the dataset. The code will then split the dataset according to the ratio in a randomized order.\n",
    "\n",
    "The steps for this part is as follows:\n",
    "> 1. Calculate number of rows to be taken\n",
    "> 2. Obtain an array of randomized indexes\n",
    "> 3. Split the dataset according to the number of rows and the randomized index.\n",
    "> 4. Return the splitted dataset\n",
    "\n",
    "#### References used\n",
    "\n",
    "https://stackoverflow.com/questions/66079043/split-dataset-without-using-scikit-learn-train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to split dataset into 8:2 training to testing dataset ratio\n",
    "def split_dataset(X, y):\n",
    "    # i will be the number of training datas\n",
    "    i = int((1 - 0.2) * X.shape[0])\n",
    "\n",
    "    # Generates random numbers based on the numbers of data\n",
    "    o = np.random.permutation(X.shape[0])\n",
    "\n",
    "    \"\"\" The following lines will basically rearrange the whole X and y dataset based on the randomized order\n",
    "        Then, we will split it based on the number of training size\n",
    "    \"\"\"\n",
    "    X_train, X_test = np.split(np.take(X, o, axis=0), [i])\n",
    "    y_train, y_test = np.split(np.take(y, o), [i])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction will return the predicted values of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w, X):\n",
    "    \"\"\" Pass two arguments\n",
    "        Arguments:\n",
    "            w: weights\n",
    "            X: input features\n",
    "        Returns:\n",
    "            yhat: predicted values\n",
    "    \"\"\"\n",
    "    yhat = np.matmul(X, w)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function of the model\n",
    "\n",
    "This loss function will only return the loss of the model. The loss function returned is Mean Squared Error divided by two for a smaller number and mathematical ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, yhat):\n",
    "    \"\"\" Pass two arguments\n",
    "        Arguments:\n",
    "            y: responses\n",
    "            yhat: predicted value\n",
    "        Returns:\n",
    "            loss: loss value\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    loss = np.sum((y - yhat)**2) / (2 * n)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[521.7524953985239, 322.50180723637226, 201.4346610878042, 127.77413811637015, 82.89575251534623, 55.515048908575594, 38.78616544038516, 28.550567276411922, 22.278781544389332, 18.43013982121879, 16.06494273361282, 14.60923315354491, 13.71194421627015, 13.158031550834504, 12.815578100965148, 12.603541150917085, 12.472058504225092, 12.390406278388454, 12.339624855556345, 12.307996815349506, 12.288269750588274, 12.275948166206735, 12.26824135562696, 12.263414368756752, 12.260387041853546, 12.258485910751022, 12.25729048794587, 12.256537870269343, 12.25606345682502, 12.255764054447996, 12.25557488327437, 12.255455225262606, 12.25537945455816, 12.255331423823828, 12.255300946191301, 12.255281587623031, 12.255269279796503, 12.255261447447817, 12.255256458696296, 12.255253278397044, 12.255251249276844, 12.255249953592989, 12.255249125593558, 12.255248596064966, 12.255248257169098, 12.255248040123906, 12.25524790102264, 12.255247811815527, 12.255247754569387, 12.255247717810475, 12.255247694192622, 12.255247679009125, 12.255247669242394, 12.255247662956519, 12.255247658908761, 12.255247656300869, 12.255247654619806, 12.255247653535644, 12.255247652836106, 12.255247652384526, 12.25524765209288, 12.25524765190444, 12.255247651782632, 12.25524765170386, 12.2552476516529, 12.255247651619916, 12.255247651598557, 12.255247651584723, 12.25524765157576, 12.255247651569945, 12.255247651566181, 12.255247651563737, 12.255247651562147, 12.255247651561117, 12.255247651560449, 12.255247651560017, 12.255247651559735, 12.25524765155955, 12.25524765155943, 12.255247651559353, 12.255247651559303, 12.255247651559268, 12.255247651559248, 12.255247651559234, 12.255247651559225, 12.255247651559216, 12.255247651559216, 12.25524765155921, 12.25524765155921, 12.255247651559209, 12.255247651559209, 12.255247651559207, 12.255247651559209, 12.255247651559207, 12.255247651559207, 12.255247651559207, 12.255247651559207, 12.255247651559207, 12.255247651559207, 12.255247651559207]\n",
      "\n",
      "Estimated weights: [ 9.69314818 11.89251878 -0.11181349 -0.0567869  36.86927177  0.18693749](6,)\n",
      "The loss of the current model: 13.499727930997407\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Read data from csv file\n",
    "    data = pd.read_csv(\"assignment1_dataset.csv\", sep=\",\")\n",
    "    data = data[[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"response\"]]\n",
    "    predict = \"response\"\n",
    "\n",
    "    # Defining the x and y data as well as number of epochs\n",
    "    x = data.drop([predict], 1).values\n",
    "    y = data[predict]\n",
    "    epochs = 100\n",
    "    \n",
    "    # We are adding a data with value 1 in front of the current data to allow for the calculation of bias.\n",
    "    # This will be helpful during prediction when we use np.matmul to calculate our predictions\n",
    "    x0 = np.ones(len(data))\n",
    "    x = np.concatenate([np.vstack(x0),x], axis=1)\n",
    "\n",
    "    # Splits the dataset and train the model, after that, use the model to predict with the test dataset.\n",
    "    X_train, X_test, y_train, y_test = split_dataset(x, y)\n",
    "    weights, hist_loss = train_model(X_train, y_train, 0.2, epochs)\n",
    "    print(hist_loss)\n",
    "    print(\"\\nEstimated weights: \" + str(weights) + str(weights.shape))\n",
    "\n",
    "    prediction = prediction(weights, X_test)\n",
    "    loss = loss_fn(y_test, prediction)\n",
    "    print(\"The loss of the current model: \" + str(loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.7642162 , -1.01620947,  0.14940999, -0.05011893,\n",
       "        -0.57812661],\n",
       "       [ 1.        ,  0.76387973, -1.15950917, -0.72149225, -0.65406671,\n",
       "        -0.43167031],\n",
       "       [ 1.        ,  0.51932888, -0.66462118, -1.69490367,  1.33977899,\n",
       "         0.18276429],\n",
       "       ...,\n",
       "       [ 1.        ,  0.34318091,  0.43124139, -0.05471514,  0.94542335,\n",
       "        -2.4746844 ],\n",
       "       [ 1.        ,  0.39102139,  0.49414714,  0.10640306, -0.65227822,\n",
       "        -0.20013865],\n",
       "       [ 1.        , -0.3761683 , -0.05426566, -0.88017593, -0.33424598,\n",
       "        -0.04344723]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxV9Z3/8dc7l4SEQHBhSQQqSBBFQWipdJu2blUcR+2vv1b76GItM7QdW+2Mv2m10/kNzozTzvw6Hbs51dpa2rrUbkqdoUppqWPHYkPBBRAIuFHDYi0CIlvy+f1xTsIFknATcnOTnPfz8biPe873LPfzvYTzud/v9yyKCMzMzADKSh2AmZn1HU4KZmbWxknBzMzaOCmYmVkbJwUzM2vjpGBmZm2cFKzHSFoo6YqeXjfrJL1P0oOljqMYJM2T9L1Sx2EHOClknKSdea8WSa/mzb+vK/uKiNkRMb+n1+0KSW+XtLGn91tKEXFHRLzjaPcjKSTVd7L8Q5KaD/mb2CnphKP9bOs/BpU6ACutiBjaOi3pGeDPI+Lnh64naVBE7O/N2KwkHomIt5Q6CCsdtxSsXa2/uCV9WtIm4HZJx0q6X9JWSX9Mp8fmbbNE0p+n0x+S9LCkL6TrPi1pdjfXnSDpIUk7JP1c0te60+Ug6dT0c7dJWinp4rxlF0palX7G7yX9n7R8RFrPbZJekvTfktr9fyPpS5Kel7Rd0jJJf5K3rErS/LR+qyV9Kr9FI+k6SevTz18l6Z15yz4k6eG8+ZD0UUnr0v19TZLSZfWSfiXpZUkvSvp+Wv5Quvlj6a//y7rx/T0j6fo0vj9Kul1SZd7yv5DUmH5PC/JbGJJOk7QoXbZZ0mfydl0h6Ttp3VdKmpm33afTf48dktZIOqercVvXOClYZ2qB44ATgbkkfy+3p/OvAV4FvtrJ9rOANcAI4F+Bb7YevLq47p3Ao8DxwDzgA12tiKRy4KfAg8Ao4BPAHZImp6t8E/hIRAwDTgd+kZZfC2wERgKjgc8AHd0b5rfAdJLv7E7gB3kHzb8HxgMnAecB7z9k2/XAnwDDgRuA70mq66RKFwGvB84A3gOcn5b/Y1rHY4GxwFcAIuKt6fIzImJoRHy/k3135n3pZ00ETgY+CyDpbOBzaSx1wLPA3emyYcDPgZ8BJwD1wOK8fV6crnsMsID0byr9t/k48Pr03+V84Jluxm2Figi//CIiIPkPd246/XZgL1DZyfrTgT/mzS8h6X4C+BDQmLdsCMnBtLYr65Ikn/3AkLzl3wO+10FMbwc2tlP+J8AmoCyv7C5gXjr9HPARoOaQ7f4BuA+o78b3+UeSgzDABuD8vGV/3l6cectXAJfkfT8P5y0L4C158/cA16XT3wFuBca2s8/orB7p5+wHtuW91h/y9/HRvPkLW5eTJNV/zVs2FNhHkgjfCyzv4DPnAT/Pm58CvJpO1wNbgHOB8lL//8jKyy0F68zWiNjdOiNpiKRbJD0raTvwEHCMpFwH229qnYiIXenk0C6uewLwUl4ZwPNdrAfpfp6PiJa8smeBMen0u0gOcs+m3S9vTMv/H9AIPChpg6TrOvoASdemXUMvS9pG8qt/RP7nd1QHSR+UtCLtptpG0loZQcc25U3v4sD3+ilAwKNpV8yHO9lHe34TEcfkvSYesjw/7mdJ6kX6/mzrgojYCfyB5PsdR9ISKrQulUrGsBqBT5Ikji2S7pYHvYvOScE6c2g3ybXAZGBWRNQArV0SHXUJ9YQm4DhJQ/LKxnVjPy8A4w4ZD3gN8HuAiPhtRFxC0rV0L8mvbyJiR0RcGxEnAX8G/HV7/drp+MGnSbpPjo2IY4CXOfDdNJF05xxWB0knAt8g6So5Pt32SbrxvUbEpoj4i4g4gaTlc7M6OeOoG/K/+9eQfK+k7ye2LpBUTdLd93uSRHJocilIRNwZycD3iSR/j//Snf1Y4ZwUrCuGkYwjbJN0HEk/eVFFxLNAAzBPUkX6C/7PjrSdpMr8F8mYxCvApySVS3p7up+70/2+T9LwiNgHbAea0/1clA7eKq+8uZ2PHEbS9bIVGCTp/wI1ecvvAa5XMlg/hiQBtKomOeBtTT/zSpKWQpdJercODP7/Md1va7ybScY0jsZVksam//6fAVrHJu4ErpQ0XdJg4J+BpRHxDHA/UCvpk5IGSxomaVYBdZks6ex0f7tJ/vba++6tBzkpWFfcBFQBLwK/IRk47A3vA95I0h3xTyQHoj2drD+G5ACS/xpHMqA5myT+m4EPRsRT6TYfAJ5Ju8U+yoGB4Ekkg6Q7gUeAmyNiSTuf+QCwEFhL0o2ym4O7Wv6BZMD66XR/P2ytQ0SsAv4t3f9mYCrw606/kY69HlgqaSfJoO01EfF0umweMD/tonpPB9u/UYdfp/D6vOV3kgxkb0hf/5TWYTHwd8CPSFpFE4HL02U7SAbX/4ykq2gdcFYBdRkMfJ7k32sTSSvuM51uYUdN6YCOWb+Rnmb5VEQUvaVSLJI+BlweEW8rdSyFUifXsdjA4ZaC9XmSXi9poqQySRcAl5D0+/cbkuokvTmtw2SS8ZmflDous0P5imbrD2qBH5MMXG4EPhYRy0sbUpdVALcAE0hO9bybpAvLrE9x95GZmbVx95GZmbXp191HI0aMiPHjx5c6DDOzfmXZsmUvRsTI9pb166Qwfvx4GhoaSh2GmVm/IunZjpa5+8jMzNo4KZiZWRsnBTMza+OkYGZmbZwUzMysTb8++6i7WppbaFzYSNPyJupm1FE/u56ynPOjmVnmkkJLcwvfP/92dixdxUmvPMGS6qksmzWFyx640onBzDIvc0fBxoWNvPybVczZeRPnxiLm7LyJ7UtX07iwsdShmZmVXOaSQtPyJup3PUGO5KmMOVqY+MrjbFqx6QhbmpkNfJlLCnUz6mgcMpXmtOrNlLG+ehq102tLHJmZWellbkyhfnY9//O6yXz5kU9w+v5VbKieRs2sU6mf3ZOPsTUz658ylxTKcmVc9NMPcumHf0TZcWcx++JTffaRmVkqc0kBoLqynI31xzB49imc/LaJpQ7HzKzPyOTP48GDkmq/ure5xJGYmfUtRU0Kkp6R9ISkFZIa0rLjJC2StC59PzZv/eslNUpaI+n8YsVVViYqy8vYvc9JwcwsX2+0FM6KiOkRMTOdvw5YHBGTgMXpPJKmAJcDpwEXADdLyhUrqCEVg3jVScHM7CCl6D66BJifTs8HLs0rvzsi9kTE00AjcGaxgqgqz7HL3UdmZgcpdlII4EFJyyTNTctGR0QTQPo+Ki0fAzyft+3GtOwgkuZKapDUsHXr1m4HVlle5paCmdkhin320Zsj4gVJo4BFkp7qZF21UxaHFUTcCtwKMHPmzMOWF6qqIsdutxTMzA5S1JZCRLyQvm8BfkLSHbRZUh1A+r4lXX0jMC5v87HAC8WKrao855aCmdkhipYUJFVLGtY6DbwDeBJYAFyRrnYFcF86vQC4XNJgSROAScCjxYqv0knBzOwwxew+Gg38RFLr59wZET+T9FvgHklzgOeAdwNExEpJ9wCrgP3AVRFRtKP2kIocW3fsKdbuzcz6paIlhYjYAJzRTvkfgHM62OZG4MZixZTP3UdmZofL5BXNkAw0+4pmM7ODZTYpeEzBzOxwmU0KVeU53+bCzOwQmU4K+5qDfc0tpQ7FzKzPyG5SqEhuq+QuJDOzAzKfFHxVs5nZAdlNCuVuKZiZHcpJwUnBzKxNZpNCZeuYgruPzMzaZDYptLUUnBTMzNpkNikM8dlHZmaHyWxS8JiCmdnhMpsUKt19ZGZ2mMwmhbbrFNxSMDNrk92kkLYUdrmlYGbWJrNJodJjCmZmh8lsUsiVicGDypwUzMzyZDYpQDKu4HsfmZkdkO2k4AftmJkdxElhn5+nYGbWKtNJobI8x6t795c6DDOzPiPTSWFIhbuPzMzyZTopVFXkfEWzmVmeTCeFSo8pmJkdJNNJoao859tcmJnlyXxS2OWBZjOzNtlOCh5TMDM7SOaTwm6PKZiZtcl2UijPsbe5hf3NTgxmZtALSUFSTtJySfen88dJWiRpXfp+bN6610tqlLRG0vnFjq319tm79zspmJlB77QUrgFW581fByyOiEnA4nQeSVOAy4HTgAuAmyXlihlYZUXrMxU82GxmBkVOCpLGAn8K3JZXfAkwP52eD1yaV353ROyJiKeBRuDMYsbX1lLY65aCmRkUv6VwE/ApIP+oOzoimgDS91Fp+Rjg+bz1NqZlB5E0V1KDpIatW7ceVXBVftCOmdlBipYUJF0EbImIZYVu0k5ZHFYQcWtEzIyImSNHjjyqGIdUOCmYmeUbVMR9vxm4WNKFQCVQI+l7wGZJdRHRJKkO2JKuvxEYl7f9WOCFIsZ34JGcvlbBzAwoYkshIq6PiLERMZ5kAPkXEfF+YAFwRbraFcB96fQC4HJJgyVNACYBjxYrPkiuUwB8qwszs1QxWwod+Txwj6Q5wHPAuwEiYqWke4BVwH7gqogo6tG6dUxhl1sKZmZALyWFiFgCLEmn/wCc08F6NwI39kZM4IFmM7NDZfqK5sqKpPpOCmZmiUwnhSEVSUNpt7uPzMyAjCeFykFuKZiZ5ct0UhiUK6MiV+aBZjOzVKaTAkBleZlPSTUzS2U+KfhBO2ZmBzgplOc8pmBmlnJSqBjkpGBmlnJSKC9z95GZWcpJocLdR2ZmrZwUyj3QbGbWKvNJobI851NSzcxSmU8KPvvIzOyAzCeFIR5TMDNrk/mkUFmR820uzMxSXUoKksok1RQrmFKoKs+xd38LzS2HPQ7azCxzjpgUJN0pqUZSNclT0dZI+pvih9Y7Wh+048FmM7PCWgpTImI7cCnwX8BrgA8UNape1PqcZo8rmJkVlhTKJZWTJIX7ImIfMGD6WtoeyelxBTOzgpLCLcAzQDXwkKQTge3FDKo3uaVgZnbAoCOtEBFfBr6cV/SspLOKF1LvckvBzOyAQgaar0kHmiXpm5J+B5zdC7H1irak4JaCmVlB3UcfTgea3wGMBK4EPl/UqHrR4JwY27iNp760lLX3r6WluaXUIZmZlcwRu48Ape8XArdHxGOS1NkG/UVLcwvLP/hD3rV0NWP2r2LJt6aybNYULnvgSspymb+uz8wyqJAj3zJJD5IkhQckDQMGxM/pxoWN7F++lqv3fYXzYhFzdt7E9qWraVzYWOrQzMxKopCkMAe4Dnh9ROwCKki6kPq9puVN1O96glya43K0MPGVx9m0YlOJIzMzK40jJoWIaAHGAp+V9AXgTRHxeNEj6wV1M+rYUD2V5vRraKaM9dXTqJ1eW+LIzMxK44hjCpI+D7weuCMtulrSmyLi+qJG1gvqZ9ezbNYUvvzQJzh9/yo2VE+jZtap1M+uL3VoZmYloYjOL06W9DgwPW0xICkHLI+Iab0QX6dmzpwZDQ0NR7WPluYW3vnhHzFldwtXfmAG9bPrPchsZgOapGURMbO9ZYWcfQRwDPBSOj28R6LqI8pyZex9bS1bj6ni5ItOLnU4ZmYlVchP4s8ByyV9W9J8YBnwz0faSFKlpEclPSZppaQb0vLjJC2StC59PzZvm+slNUpaI+n87laqq2oqB7H91X299XFmZn1WIQPNdwFvAH6cvt4IPF3AvvcAZ0fEGcB04AJJbyA5k2lxREwCFqfzSJoCXA6cBlwA3Jx2VRXd8KpyXnZSMDMr7CE7EdEUEQsi4r6I2AT8oIBtIiJ2prPl6SuAS4D5afl8kruvkpbfHRF7IuJpoBE4s/CqdJ+TgplZorsjqgVd0SwpJ2kFsAVYFBFLgdER0QRJsgFGpauPAZ7P23xjWnboPudKapDUsHXr1m6Gf7DhVeVs3+2kYGbW3aRQ0PMUIqI5IqaTXOdwpqTTO1m9vURz2OdExK0RMTMiZo4cObKwaI+gpqqcXXub2ef7HplZxnV49pGkn9L+wV/A8V35kIjYJmkJyVjBZkl1EdEkqY6kFQFJy2Bc3mZjgRe68jndNbyqHICXX93HiKGDe+Mjzcz6pM5OSf1CN5cBIGkksC9NCFXAucC/AAuAK0jutHoFcF+6yQLgTklfBE4AJgGPHrEGPcBJwcws0WFSiIhfHeW+64D56RlEZcA9EXG/pEeAeyTNAZ4D3p1+3kpJ9wCrgP3AVRHRKw85aE0KPi3VzLKu0IvXuiy9P9KMdsr/AJzTwTY3AjcWK6aO1FQlX4PPQDKzrPP9HDi4+8jMLMucFEjOPgJ3H5mZFXKX1PbOQnoZaABuiYjdxQisN9VUpklh9/4SR2JmVlqFtBQ2ADuBb6Sv7cBm4OR0vt+rLM8xeFCZu4/MLPMKGWieERFvzZv/qaSHIuKtklYWK7DeNryqnJd3OSmYWbYV0lIYKek1rTPp9Ih0dm9RoioB3//IzKywlsK1wMOS1pNczTwB+EtJ1Ry4sV2/5/sfmZkVkBQi4r8kTQJOIUkKT+UNLt9UzOB60/CqcjZt7/dj5mZmR6XQi9deB4xP158miYj4TtGiKoGaqnLWbN5R6jDMzEqqkFNSvwtMBFYArbedCGBAJQWPKZiZFdZSmAlMiYiCbpfdX9VUlbNzz35aWoKysoIeF2FmNuAUcvbRk0BtsQMpteFV5UTADl/AZmYZVkhLYQSwStKjJM9dBiAiLi5aVCVQU3ngpnjDh5SXOBozs9IoJCnMK3YQfYFvimdmVtgpqUf7XIV+oe2ZCr5WwcwyrLPHcT4cEW+RtIODb4gnICKipujR9aLWLiO3FMwsyzp78tpb0vdhvRdO6bTeKdVJwcyyrKCL19JHao7OXz8initWUKXgMQUzs8IuXvsE8Pckt8tuSYsDmFbEuHrdkIocg8rkB+2YWaYV0lK4BpicPlt5wJLkq5rNLPMKuXjteZInrQ14TgpmlnWFtBQ2AEsk/ScHX7z2xaJFVSLDqsr9SE4zy7RCksJz6asifQ1YbimYWdYVcvHaDb0RSF8wvKqc51/aVeowzMxKprOL126KiE9K+ikHX7wGDLx7HwEMrxrkloKZZVpnLYXvpu9f6I1A+oKaynK2v7qPiEDy7bPNLHs6u6J5WfqeiXsfQdJ9tL8l2LW3merBhT6Uzsxs4Cjk4rVJwOeAKUBla3lEnFTEuEoi/6pmJwUzy6JCrlO4HfgPYD9wFsljOL/b6Rb9lG91YWZZV0hSqIqIxYAi4tmImAecXdywSqOm9fbZTgpmllGFJIXdksqAdZI+LumdwKgjbSRpnKRfSlotaaWka9Ly4yQtkrQufT82b5vrJTVKWiPp/G7XqptqKnKMbdzGyn//DWvvX0tLc8uRNzIzG0AKSQqfBIYAVwOvA94PXFHAdvuBayPiVOANwFWSpgDXAYsjYhKwOJ0nXXY5cBpwAXBzenfWXtHS3ELDB37Auxb8lnFf+xJL3nsL3z//dicGM8uUTpNCelB+T0TsjIiNEXFlRLwrIn5zpB1HRFNE/C6d3gGsBsYAlwDz09XmA5em05cAd0fEnoh4GmgEzuxWrbqhcWEje5et4ep9X+G8WMScnTexfelqGhc29lYIZmYl12FSkDQoIpqB1+koT9qXNB6YASwFRkdEEySJgwNdUWNIbr7XamNadui+5kpqkNSwdevWownrIE3Lm5i46wly6d3Bc7Qw8ZXH2bRiU499hplZX9dZS+HR9H05cJ+kD0j6X62vQj9A0lDgR8AnI2J7Z6u2U9beldS3RsTMiJg5cuTIQsM4oroZdWyonkpz+pU0U8b66mnUTq/tsc8wM+vrCjkZ/zjgDyRnHAXpM5qBHx9pQ0nlJAnhjohoXX+zpLqIaJJUB2xJyzcC4/I2Hwu8UFAtekD97HqWzZrCVx++mil7VrJh6DRqZp1K/ez63grBzKzkOksKoyT9NfAkB5JBq8N+wR8q7XL6JrD6kNtsLyAZqP58+n5fXvmdkr4InABM4kBrpejKcmVc9sCVfPr6B2lYcQZ/d/WbqJ9dT1mukLF4M7OBobOkkAOGUmC3TjveDHwAeELSirTsMyTJ4B5Jc0huyf1ugIhYKekeYBXJmUtXpWMavaYsV8aIs8dzb3kL9RdOoqzM9z8ys2zpLCk0RcQ/dHfHEfEw7ScUgHM62OZG4MbufmZPqK2pZF9z8NKuvYwYOriUoZiZ9brO+kYy+TO5dnhye6dNL+8ucSRmZr2vs6TQ7q/5ga62xknBzLKrw6QQES/1ZiB9RV3aUmja7qRgZtnjU2sOcfzQweTKxGa3FMwsg5wUDpErE6OHDabJScHMMshJoR2jh1eyafurpQ7DzKzXOSm0o254pQeazSyTnBTaMbrGScHMsslJoR11wyt5ZW8zO3b7CWxmli1OCu2oHV4F+FoFM8seJ4V2tF3A5msVzCxjnBTa0XYBm1sKZpYxTgrtGFWT3AjPF7CZWdY4KbRj8KAcx1dX+FYXZpY5TgodGF1T6ZaCmWWOk0IH6oZXekzBzDLHSaEDo4dXstndR2aWMU4KHairqeQPr+xl975efSKomVlJOSl0YHR6WuqW7XtKHImZWe9xUuhA7dAKxjZu4+EbH2Lt/WtpaW4pdUhmZkU3qNQB9EUtzS2sm3sv7/rNakbuX8WSb0xl2awpXPbAlZTlnEfNbODyEa4djQsb2f+7tVy97yucF4uYs/Mmti9dTePCxlKHZmZWVE4K7Wha3sTEXU+QI+kyytHCxFceZ9OKTSWOzMysuJwU2lE3o44N1VNpTr+eZspYXz2N2um1JY7MzKy4PKbQjvrZ9SybNYWbf30Nk3c/ydNDp1Ez61TqZ9eXOjQzs6JyUmhHWa6Myx64kttueoSv3Xcqn/rYG3jje07zILOZDXg+ynWgLFfG6/73FB570wnsOmOUE4KZZYKPdJ2YXDsMgDWbtpc4EjOz3uGk0Imhgwcx7rgqntq0o9ShmJn1CieFI5g8usZJwcwyo2hJQdK3JG2R9GRe2XGSFklal74fm7fsekmNktZIOr9YcXXVKbXDePrFV9iz3zfGM7OBr5gthW8DFxxSdh2wOCImAYvTeSRNAS4HTku3uVlSroixFWxy7TCaW4LGLTtLHYqZWdEVLSlExEPAS4cUXwLMT6fnA5fmld8dEXsi4mmgETizWLF1xSltg83uQjKzga+3xxRGR0QTQPo+Ki0fAzyft97GtOwwkuZKapDUsHXr1qIGCzBhRDUVuTKPK5hZJvSVgWa1UxbtrRgRt0bEzIiYOXLkyCKHBYNyZdSPGuqkYGaZ0NtJYbOkOoD0fUtavhEYl7feWOCFXo6tQ6fUDvO1CmaWCb2dFBYAV6TTVwD35ZVfLmmwpAnAJODRXo6tQ5Nrh7F5+x7++MreUodiZlZUxTwl9S7gEWCypI2S5gCfB86TtA44L50nIlYC9wCrgJ8BV0VEnzkH9OSR1Yxt3MZ/fvYXfgqbmQ1oimi3675fmDlzZjQ0NBT1M1qaW/juOd/kpf9Zyen7V/F09VSG+SlsZtaPSVoWETPbW+aj2hE0Lmxkz7Kn/BQ2M8sEJ4UjaFrexEmv+ClsZpYNTgpH4KewmVmW+CE7R9D6FLZv/OaTnPTKE6ytPJ3j/RQ2MxugnBSOoPUpbI0LG/m3W5aye+wwbv/qxR5kNrMByUe2ApTlyjj5opM59ZpZPHRMOdt27y91SGZmReGk0AVnTR5FBPz3uuLfc8nMrBScFLpg6pjhHF9dwS+f2nLklc3M+iGPKXRBWZl426QRrPrpWpas3c4Jr62jfna9xxfMbMBwUuiCluYWJvz7I4xbvpb9+1expHoqy3x1s5kNID6SdUHjwkYqVq7n6n1f4Vxf3WxmA5CTQhc0LW9i4i5f3WxmA5eTQhf46mYzG+g8ptAFrVc337b0rzhp5+OsrDiNUWee4qubzWzAcFLogvyrmx96YB0/bNrGpz7zNg8ym9mA4aTQRa1XN9dfOIm7/m0Jd339twwfu546n55qZgOAk0J3RXDxD1bRsmIde316qpkNED56dVPjwkYqV2/ww3fMbEBxUuimpuVNTPTDd8xsgHFS6KZDT0/dR44nyqfz4lMvsvb+tbQ0t5Q4QjOzrlNElDqGbps5c2Y0NDSU5LNbmlv4/vm3s33pak7a+TjLNYMqXuVUnmJD9VSGeXzBzPooScsiYmZ7y3zE6qbW01PPumsuO97/UYYN3stfxtc4NxZx5c4vseXXa7n3invdajCzfsVJ4Si0np56/MnHM2nPSnK00IL4Ie+hfPcOht3xdZa89xa+f/7tTgxm1i/4lNQeUDejjiXVU2neuZj11LODYXyEW8jRwr6dv+DmX1/LvVfcy5R3TwFg8+ObqZvh6xrMrO9xUugB+be/qNj5EhPYcFirYegdX+f+u2dQxW4mt6zml0Om8qv6CUx65+lt905ysjCzUnNS6AH5t7948vtPsv6HD3P27l8c1GpYTz3PNE9gDrchgi2vjOCPj+1l32MLuD93IFksqZ5Kw5mn8tqr38LmxzczetpogD45XTejjpPecRIbHtxA0/KmPhFTf4qvP8Xa1+PrT7H2ZHzF+BHps496WP5ZSRU7X2Isz3MeP+dXvJV9lHMui1nLySzh7czhNtZT3zado4V95Lip7Fqqy/cyac9KHitLzmo6ueUpHkuTx8nNq0s+PbllNeuHTGVXxTFU79vGhJ1PlDym/hRff4q1r8fXn2Ltyfgmt6zu9pmOnZ19lJs3b15PHQ973a233jpv7ty5pQ7jICoTp71vOsPPmMD23DFsXLuHGfsfZR8VLOe1TGc5q5jCcF6mng08yWlt0wDrmcTGGMNHmm+mhRxNUcvcuCVv+ut9Yrqe9Qzd9xLP7h7N3L1f7RMx9af4+lOsfT2+/hRrT8ZXz3qm713KI1vrGX7GBI4/+fiCj1M33HBD07x5825tb5k7roug9aykS799KcPffBq3Df0rnuVEtueO5eu5j7OZWtZwKs2UUccmNjCx7SK4F6hjEuvI0UITtZzE+j45DbCZ0UxmTZ+JqT/F159i7evx9adYezI+KM6dFJwUiij/WobB//hZLvrRhzjnRx9j9A1/SeUZJ3Nb9cHJ4uc6j8cqZ7E2N+WwhNHXpgFGs5m1nNJnYupP8fWnWPt6fP0p1p6MD4rzoK8+N6Yg6U7U3vMAAAaVSURBVALgS0AOuC0iPt/Run1xTKFQLc0tNC5sZNOKTYyaOgqALU9sYdTUUfzuyw+z49GnOGnn4zyWe20yptC8uk9NT25ZTeOQabxaMZwhe1/mpFf6Vqx9Pb7+FGtfj68/xdqT8U1uWc366mnUzDq1R8cU+lRSkJQD1gLnARuB3wLvjYhV7a3fn5NCZzpLGH1punZ6bdtZFH0x1r4eX3+Kta/H159i7cn4aqfXduvso/6UFN4IzIuI89P56wEi4nPtrT9Qk4KZWTH1p3sfjQGez5vfmJa1kTRXUoOkhq1bt/ZqcGZmA11fSwpqp+ygpkxE3BoRMyNi5siRI3spLDOzbOhrSWEjMC5vfizwQoliMTPLnL6WFH4LTJI0QVIFcDmwoMQxmZllRp+691FE7Jf0ceABklNSvxURK0sclplZZvSps4+6StJW4NkubDICeLFI4fRlWax3FusM2ax3FusMR1fvEyOi3UHZfp0UukpSQ0enYQ1kWax3FusM2ax3FusMxat3XxtTMDOzEnJSMDOzNllLCu3eKjYDsljvLNYZslnvLNYZilTvTI0pmJlZ57LWUjAzs044KZiZWZvMJAVJF0haI6lR0nWljqcYJI2T9EtJqyWtlHRNWn6cpEWS1qXvx5Y61mKQlJO0XNL96fyArrekYyT9UNJT6b/5Gwd6nQEk/VX69/2kpLskVQ60ekv6lqQtkp7MK+uwjpKuT49taySdfzSfnYmkkD6n4WvAbGAK8F5JU0obVVHsB66NiFOBNwBXpfW8DlgcEZOAxen8QHQNsDpvfqDX+0vAzyLiFOAMkroP6DpLGgNcDcyMiNNJ7nxwOQOv3t8GLjikrN06pv/HLwdOS7e5OT3mdUsmkgJwJtAYERsiYi9wN3BJiWPqcRHRFBG/S6d3kBwkxpDUdX662nzg0tJEWDySxgJ/CtyWVzxg6y2pBngr8E2AiNgbEdsYwHXOMwiokjQIGEJy08wBVe+IeAh46ZDijup4CXB3ROyJiKeBRpJjXrdkJSkc8TkNA42k8cAMYCkwOiKaIEkcwKjSRVY0NwGfgvSJ5omBXO+TgK3A7WmX2W2SqhnYdSYifg98AXgOaAJejogHGeD1TnVUxx49vmUlKRzxOQ0DiaShwI+AT0bE9lLHU2ySLgK2RMSyUsfSiwYBrwX+IyJmAK/Q/7tMjijtR78EmACcAFRLen9poyq5Hj2+ZSUpZOY5DZLKSRLCHRHx47R4s6S6dHkdsKVU8RXJm4GLJT1D0jV4tqTvMbDrvRHYGBFL0/kfkiSJgVxngHOBpyNia0TsA34MvImBX2/ouI49enzLSlLIxHMaJImkj3l1RHwxb9EC4Ip0+grgvt6OrZgi4vqIGBsR40n+bX8REe9nANc7IjYBz0uanBadA6xiANc59RzwBklD0r/3c0jGzgZ6vaHjOi4ALpc0WNIEYBLwaLc/JSIy8QIuBNYC64G/LXU8RarjW0iajY8DK9LXhcDxJGcrrEvfjyt1rEX8Dt4O3J9OD+h6A9OBhvTf+17g2IFe57TeNwBPAU8C3wUGD7R6A3eRjJnsI2kJzOmsjsDfpse2NcDso/ls3+bCzMzaZKX7yMzMCuCkYGZmbZwUzMysjZOCmZm1cVIwM7M2Tgpm7ZDULGlF3qvHrhaWND7/7pdmfcmgUgdg1ke9GhHTSx2EWW9zS8GsCyQ9I+lfJD2avurT8hMlLZb0ePr+mrR8tKSfSHosfb0p3VVO0jfS5wI8KKkqXf9qSavS/dxdompahjkpmLWv6pDuo8vylm2PiDOBr5LcnZV0+jsRMQ24A/hyWv5l4FcRcQbJvYlWpuWTgK9FxGnANuBdafl1wIx0Px8tVuXMOuIrms3aIWlnRAxtp/wZ4OyI2JDefHBTRBwv6UWgLiL2peVNETFC0lZgbETsydvHeGBRJA9LQdKngfKI+CdJPwN2kty24t6I2FnkqpodxC0Fs66LDqY7Wqc9e/KmmzkwvvenJE8JfB2wLH2QjFmvcVIw67rL8t4fSaf/h+QOrQDvAx5OpxcDH4O2Z0jXdLRTSWXAuIj4JckDg44BDmutmBWTf4WYta9K0oq8+Z9FROtpqYMlLSX5UfXetOxq4FuS/obkiWhXpuXXALdKmkPSIvgYyd0v25MDvidpOMmDU/49kkdsmvUajymYdUE6pjAzIl4sdSxmxeDuIzMza+OWgpmZtXFLwczM2jgpmJlZGycFMzNr46RgZmZtnBTMzKzN/wdIe+WOPd/AjQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1, epochs, epochs)\n",
    "plt.title(\"Training Loss against Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.plot(x, hist_loss, marker=\".\", markerfacecolor=\"red\", markeredgecolor=\"purple\", markersize=10.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Mean Squred Error and R-Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 26.999455861994814\n",
      "R-Squared Error: 0.9820008441924185\n"
     ]
    }
   ],
   "source": [
    "# Loss times 2 is because our loss is divided by 2\n",
    "print(\"Mean Squared Error: \" + str(loss * 2))\n",
    "\n",
    "sst = sum((y_test - y_test.mean())**2)\n",
    "r2Error = 1 - ((loss * 2 * len(y_test))/sst)\n",
    "print(\"R-Squared Error: \" + str(r2Error))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
