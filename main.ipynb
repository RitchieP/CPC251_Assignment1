{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training model will have to split the dataset into training and test data. \n",
    "\n",
    "The training data will be used to estimate the weights, the test data will then be used to determine the loss function. In which it will also use the prediction function.\n",
    "\n",
    "https://stackoverflow.com/questions/66079043/split-dataset-without-using-scikit-learn-train-test-split\n",
    "\n",
    "https://medium.com/geekculture/linear-regression-from-scratch-in-python-without-scikit-learn-a06efe5dedb6\n",
    "\n",
    "https://www.geeksforgeeks.org/how-to-implement-a-gradient-descent-in-python-to-find-a-local-minimum/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, alpha, max_epoch):\n",
    "    \"\"\" Pass four arguments\n",
    "        Arguments:\n",
    "            X: input features\n",
    "            y: responses\n",
    "            alpha: learning rate\n",
    "            max_epoch: maximum epochs\n",
    "        Returns:\n",
    "            w: estimated weights\n",
    "            hist_loss: training loss history\n",
    "    \"\"\"\n",
    "    hist_loss = []\n",
    "    # Initialize weights with random values\n",
    "    current_weight = np.array(np.random.randint(0, 9, np.shape(X)[1]))\n",
    "\n",
    "    # We calculate the loss function for the first randomly initialized weights, and store it\n",
    "    y_pred = prediction(current_weight, X)\n",
    "    current_loss = loss_fn(y, y_pred)\n",
    "    n = len(y)\n",
    "\n",
    "    for i in range(max_epoch):\n",
    "        # Estimate the parameter using the randomly initialized weights and loss function for it\n",
    "        gradient = -(np.matmul((y-y_pred), X))/n\n",
    "        current_weight = current_weight - alpha * gradient\n",
    "\n",
    "        # Predict with the new weights, and calculate the loss function for it, and store it\n",
    "        y_pred = prediction(current_weight, X)\n",
    "        current_loss = loss_fn(y, y_pred)\n",
    "        hist_loss.append(loss_fn(y, y_pred))\n",
    "\n",
    "    return current_weight, hist_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to split dataset into 8:2 training to testing dataset ratio\n",
    "def split_dataset(X, y):\n",
    "    # i will be the number of training datas\n",
    "    i = int((1 - 0.2) * X.shape[0])\n",
    "\n",
    "    # Generates random numbers based on the numbers of data\n",
    "    o = np.random.permutation(X.shape[0])\n",
    "\n",
    "    \"\"\" The following lines will basically rearrange the whole X and y dataset based on the randomized order\n",
    "        Then, we will split it based on the number of training size\n",
    "    \"\"\"\n",
    "    X_train, X_test = np.split(np.take(X, o, axis=0), [i])\n",
    "    y_train, y_test = np.split(np.take(y, o), [i])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction will return the predicted values of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w, X):\n",
    "    \"\"\" Pass two arguments\n",
    "        Arguments:\n",
    "            w: weights\n",
    "            X: input features\n",
    "        Returns:\n",
    "            yhat: predicted values\n",
    "    \"\"\"\n",
    "    yhat = np.matmul(X, w)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loss function will only return the loss of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y, yhat):\n",
    "    \"\"\" Pass two arguments\n",
    "        Arguments:\n",
    "            y: responses\n",
    "            yhat: predicted value\n",
    "        Returns:\n",
    "            loss: loss value\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    loss = (sum((y - yhat)**2)) / (2 * n)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[533.3065122387858, 437.17367888506413, 360.5356039067252, 299.42985044194944, 250.70109036812937, 211.83638069654336, 180.8341194446207, 156.09978342713498, 136.36296517292766, 120.61135035319012, 108.03817046106029, 98.00037546644485, 89.98533547269763, 83.5843289556887, 78.47143174594446, 74.38670440631142, 71.12280106359043, 68.51430199183837, 66.42921478749085, 64.7622023469111, 63.42918603501735, 62.36304417145896, 61.51018303539746, 60.82780300351958, 60.28171857504081, 59.844619799529326, 59.494685516953474, 59.214477044020775, 58.99005545057973, 58.810277123310705, 58.66623151462608, 58.55079230270306, 58.45825902581689, 58.38407090452876, 58.32457827063212, 58.27685997453321, 58.238577496130894, 58.20785836018824, 58.18320295277013, 58.16341002781622, 58.14751714393058, 58.134753029981304, 58.12449948319827, 58.1162608862393, 58.10963981493079, 58.104317515875344, 58.10003827854254, 58.09659692242338, 58.09382877629709, 58.09160165162545, 58.08980941191739, 58.08836681965687, 58.087205406119935, 58.08627016033636, 58.08551687417395, 58.08491001307032, 58.084421007973944, 58.08402688487749, 58.083709164977876, 58.08345298183475, 58.08324637255591, 58.083079708581465, 58.08294523847397, 58.08283672059217, 58.08274912791542, 58.0826784107915, 58.08262130620168, 58.08257518438759, 58.08253792549344, 58.08250782032925, 58.08248349051912, 58.08246382423486, 58.08244792446095, 58.082435067338835, 58.08242466861847, 58.082416256634325, 58.08240945053203, 58.08240394272037, 58.082399484728555, 58.0823958758015, 58.08239295370483, 58.08239058730728, 58.082388670597055, 58.082387117853195, 58.08238585974843, 58.082384840203716, 58.082384013847616, 58.082383343965006, 58.08238280084046, 58.082382360419004, 58.082382003224446, 58.082381713485226, 58.08238147842735, 58.08238128770284, 58.082381132927786, 58.08238100730832, 58.08238090533788, 58.08238082255291, 58.082380755334796, 58.082380700748956]\n",
      "Estimated weights: [11.77083713 -0.49649204 -0.77443422 37.03907872  0.64349054]\n",
      "The loss of the current model: 60.36734494615108\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Read data from csv file\n",
    "    data = pd.read_csv(\"assignment1_dataset.csv\", sep=\",\")\n",
    "    data = data[[\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"response\"]]\n",
    "    predict = \"response\"\n",
    "\n",
    "    \n",
    "    x = data.drop([predict], 1).values\n",
    "    y = data[predict]\n",
    "    epochs = 100\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_dataset(x, y)\n",
    "    weights, hist_loss = train_model(X_train, y_train, 0.1, epochs)\n",
    "    print(hist_loss)\n",
    "    print(\"\\nEstimated weights: \" + str(weights))\n",
    "\n",
    "    prediction = prediction(weights, X_test)\n",
    "    loss = loss_fn(y_test, prediction)\n",
    "    print(\"The loss of the current model: \" + str(loss))\n",
    "\n",
    "    # testing purposes\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = split_dataset(x, y)\n",
    "    # # Initialize weights with zero with the amount of columns I have\n",
    "    # w = np.array(np.random.randint(0, 9, x.columns.shape))\n",
    "\n",
    "    # new_header = X_test.iloc[0] #grab the first row for the header\n",
    "    # new_X_test = X_test[1:] #take the data less the header row\n",
    "    # new_X_test.columns = new_header #set the header row as the df header\n",
    "\n",
    "    # print(sum(w * new_X_test))\n",
    "    # print(X_test)\n",
    "\n",
    "\n",
    "    # We calculate the loss function for the first randomly initialized weights, and store it\n",
    "    # current_loss = loss_fn(y_test, prediction(w, X_test))\n",
    "\n",
    "    # w, hist_loss = train_model(x, y, 0.2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hist_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1, epochs, epochs)\n",
    "plt.title(\"Training Loss against Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.plot(x, hist_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
